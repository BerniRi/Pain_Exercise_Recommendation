<!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>Aktiv Walter - Exercise Recommendation for individual pains</title>
        <style>
/* From extension vscode.github */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

.vscode-dark img[src$=\#gh-light-mode-only],
.vscode-light img[src$=\#gh-dark-mode-only] {
	display: none;
}

</style>
        
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item {
    list-style-type: none;
}

.task-list-item-checkbox {
    margin-left: -20px;
    vertical-align: middle;
    pointer-events: none;
}
</style>
        
    </head>
    <body class="vscode-body vscode-light">
        <h1 id="aktiv-walter---exercise-recommendation-for-individual-pains">Aktiv Walter - Exercise Recommendation for individual pains</h1>
<h2 id="introduction">Introduction</h2>
<p>The project suggests physical exercises for users who want to reduce a certain problem like back pain. The following chapters describe the project files.</p>
<h2 id="create_activity_sources_datasetipynb">Create_Activity_Sources_dataset.ipynb</h2>
<p>We used EdgeGPT (<a href="https://github.com/acheong08/EdgeGPT">https://github.com/acheong08/EdgeGPT</a>), a wrapper for the Bing Chat to gather a dataset including the columns &quot;Problem&quot;, &quot;Exercise&quot;, &quot;SourceHead&quot;, &quot;SourceLink&quot;. The data was received in json format and had to be cleaned to be used in a ML model. We cleaned the dataset manually and with the help of OpenAI's GPT3. The cleaned dataset can be found under <strong>./data/data</strong>.csv. The code for gathering the data is in <strong>Create_Activity_Sources_dataset.ipynb</strong>.</p>
<ol>
<li>The code defines a function called requestBingChat that uses the EdgeGPT library to interact with the chatbot and retrieve exercise recommendations for a given problem.</li>
<li>It creates an instance of the Chatbot class, sends a prompt to the chatbot, and retrieves a response.</li>
<li>The response is processed, removing unnecessary elements from the sources.</li>
<li>The response is converted to JSON format and added to a list called jsonList.</li>
<li>The function is closed.</li>
<li>The code iterates over the problems list, calling the requestBingChat function for each problem.</li>
<li>The resulting jsonList is saved to a JSON file called &quot;data.json&quot;. If the file already exists, the code appends the jsonList to the existing data.</li>
</ol>
<h2 id="fitness_categoriesipynb">fitness_categories.ipynb</h2>
<p>In this file we split the users of the bodyPerformance dataset into four performance groups. The groups are based on the quartiles of the &quot;Calories per kg&quot; column. The groups are stored in the &quot;category&quot; column. In a next step we test different classifiers to predict the category of a user based on the bodyPerformance dataset. The classifiers are: Random Forest Classifier (RFC), Decision Tree Classifier (DTC), XGBoost Classifier (XGBC), Logistic Regression (LR), and Support Vector Machine (SVM). The classifiers are trained and evaluated on the bodyPerformance dataset. Accuracy scores and confusion matrices are printed for each classifier. The best classifier is the Random Forest Classifier with an accuracy of 0.75. In the keyword matching part, the exercises of the exercise_dataset are matched with the exercises of the sources dataset to get relevant sources for each exercise.</p>
<h3 id="data-loading-and-preprocessing">Data Loading and Preprocessing:</h3>
<p>Two datasets are loaded: 'exercise_dataset.csv' and 'bodyPerformance.csv'.
'exercise_dataset.csv' is assigned to the DataFrame variable 'df', and 'bodyPerformance.csv' is assigned to 'dfBody'.
'category' column is created in 'df' based on quartiles of 'Calories per kg'.
Gender and class columns in 'dfBody' are encoded using mapping dictionaries.</p>
<h3 id="feature-importance">Feature Importance:</h3>
<p>ExtraTreesClassifier and XGBClassifier are used to determine feature importances in 'dfBody'.
The feature importances are visualized using bar plots.</p>
<h3 id="classification-models">Classification Models:</h3>
<p>Random Forest Classifier (RFC), Decision Tree Classifier (DTC), XGBoost Classifier (XGBC), Logistic Regression (LR), and Support Vector Machine (SVM) classifiers are trained and evaluated on 'dfBody'.
Accuracy scores and confusion matrices are printed for each classifier.</p>
<h3 id="random-forest-classifier-fine-tuning">Random Forest Classifier Fine-Tuning:</h3>
<p>GridSearchCV is used to find the best hyperparameters for the RFC.
The best model is extracted and evaluated on the test set.
The best model is saved to 'best_model.pkl' using pickle.</p>
<h3 id="keyword-extraction-and-matching">Keyword Extraction and Matching:</h3>
<p>The 'Exercise' column in 'sources' DataFrame is given unique IDs and stored in the 'exercise_id' column.
The 'exercise_id' column is filled in 'df' by matching exercise names from 'sources' with activity names in 'df'.
Unique 'exercise_id' values in 'df' are outputted.
'df' and 'sources' are saved to new CSV files.</p>
<h2 id="create_exercise_for_useripynb">Create_exercise_for_user.ipynb</h2>
<p>This notebook contains code to create a personalized exercise recommendation for a user. It uses the best model created in **fitness_categories.ipynb
** to predict the performance category of the user. Based on the pain defined by the user, an exercise is loaded from the exercise dataset (<strong>exercise_dataset_with_exercise_id.csv</strong>) in combination with a source from the sources dataset (<strong>sources_with_exercise_id.csv</strong>). The predicted exercise is matched with the sources dataset to get a source for the exercise. The source is printed to the user.</p>
<ol>
<li>
<p>Data Preparation:</p>
<ul>
<li>A dictionary <code>data</code> is created with information about an individual.</li>
<li>The dictionary is converted into a pandas DataFrame <code>x</code>.</li>
<li>The 'gender' column in the DataFrame is encoded using a mapping dictionary, converting 'M' to 0 and 'F' to 1.</li>
</ul>
</li>
<li>
<p>Model Loading and Prediction:</p>
<ul>
<li>A pre-trained model is loaded from the 'best_model.pkl' file using pickle.</li>
<li>The loaded model is used to predict the class labels for the input data <code>x</code>.</li>
<li>The predicted labels are stored in <code>y_pred</code>.</li>
</ul>
</li>
<li>
<p>Mapping the Predicted Label:</p>
<ul>
<li>A mapping dictionary is defined to map the numeric labels to corresponding classes.</li>
<li>The predicted label <code>y_pred</code> is mapped to a user-friendly class label <code>user_class</code>.</li>
</ul>
</li>
<li>
<p>Loading Additional Data:</p>
<ul>
<li>Two datasets are loaded from CSV files: 'sources_with_exercise_id.csv' and 'exercise_dataset_with_exercise_id.csv'.</li>
<li>These datasets contain information about sources and exercises, respectively.</li>
</ul>
</li>
<li>
<p>Searching for Exercise IDs:</p>
<ul>
<li>A variable <code>problem</code> is set to search for specific problems (e.g., &quot;back pain&quot;).</li>
<li>The <code>sources</code> DataFrame is filtered to find rows where the 'Problem' column contains the search keyword.</li>
<li>If any exercise IDs are found, a random one is selected, and the associated source head and link are stored in <code>sourceHead</code> and <code>sourceLink</code> variables.</li>
<li>If no exercise IDs are found, <code>-1</code> is assigned to <code>ex_id</code>.</li>
</ul>
</li>
<li>
<p>Retrieving Exercise Details:</p>
<ul>
<li>The <code>exercises</code> DataFrame is filtered to find rows where the exercise ID matches <code>ex_id</code>.</li>
<li>If any exercises are found, a random one is selected from the filtered DataFrame.</li>
<li>If no exercises are found, a random exercise is selected from the entire <code>exercises</code> DataFrame.</li>
</ul>
</li>
<li>
<p>Output Summary:</p>
<ul>
<li>The variables <code>problem</code>, <code>exercise</code>, <code>user_class</code>, <code>sourceHead</code>, and <code>sourceLink</code> are printed.</li>
</ul>
</li>
</ol>
<h2 id="create_exercise_for_user_with_llmipynb">Create_exercise_for_user_with_LLM.ipynb</h2>
<p>This file contains the same code as <strong>Create_exercise_for_user.ipynb</strong> but with the addition of a language model. The language model is used to generate a personalized exercise recommendation for a user. This recommendation should be used as a push notification for a mobile app to motivate the user to do something against his/her pain.</p>
<h2 id="falcon-7bipynb">falcon-7b.ipynb</h2>
<p>This notebook contains code to download the Falcon-7b-Instruct model from Huggingface and some test prompts. It shows that the 8-bit quantized model can run inference with less than 4GB VRAM. It was executed on Kaggle cloud.</p>

        
        
    </body>
    </html>